% +--------------------------------------------------------------------+
% | Sample Chapter 3
% +--------------------------------------------------------------------+

\cleardoublepage

% +--------------------------------------------------------------------+
% | Replace "This is Chapter 3" below with the title of your chapter.
% | LaTeX will automatically number the chapters.
% +--------------------------------------------------------------------+

\chapter{Diseño de la aplicación}
\label{makereference3}

\section{Stakeholders}
\label{makereference3.1}

\section{Escenarios}
\label{makereference3.2}
Antes de decidir como implementaríamos nuestra aplicación decidimos que sería importante establecer una serie
de escenarios en los que podría ser usada. Tras esto pudimos ponernos de acuerdo en que funcionalidades incluiríamos y que 
éstas se ajusten a las necesidades de los usuarios. Además estos escenarios deberían usar la \textbf{realidad aumentada} para que 
les aporte valor, ya que, como hemos expuesto anteriormente en el capítulo 2, el grueso de nuestra aplicación se centra en esta tecnología.

\paragraph{Escenario 1. Usando la aplicación en casa:\\}
\begin{itemize}
    \item Te apetece ir al cine y encuentras el cartel de una película que te interesa ver en cualquier lado (ordenador, revista, etc.), sacas tu móvil con la aplicación y 
    la escaneas, con la realidad aumentada te saldrán los distintos paneles y botones que te facilitan información sobre la película:
    \begin{enumerate}
        \item Ver el tráiler.
        \item Valoración que tiene en páginas web, como por ejemplo \textbf{IMDB}.
        \item Botón para crear un plan para ir a ver esa película o unirte a uno que uno de tus amigos ya haya creado para esa misma película.
        \item Botón para guardar la película en tu lista de películas guardadas.
    \end{enumerate}
    \item Te apetece ir al cine y has visto varias películas que te interesan, pero no sabes a cuál ir, captas todas ellas con la aplicación 
    y para cada una de ellas tendrás las opciones anteriores más poder añadirlas a un plan ya creado, crear un nuevo plan o guardarlas.
\end{itemize}

\paragraph{Escenario 2. Usando la aplicación en la calle.\\}
Vas por la calle y ves el anuncio de una película en cualquier sitio, ya sea en el metro, paradas de autobús, en una fachada o que simplemente pases 
por delante de un cine. Sacas tu aplicación, escaneas dicha película y podrás hacer lo mismo que cuando estás en casa, pero si vas con prisa coge más peso 
el guardar la película en tu lista de películas para posteriormente añadirla a un plan o poder ver la información de ésta, además de la opción de poder valorarla.



\section{Requisitos funcionales}
\label{makereference3.3}

\paragraph{Planes:\\}

Los planes están compuestos por una película, un usuario creador del plan, y los usuarios que se hayan unido. El plan
es creado debido a la necesidad que tiene un usuario de querer ver una película específica con una serie de usuarios que 
entrarán en el plan por tener interés en ver dicha película debido a su afinidad con la misma.
\\
\textbf{Funciones:}
\begin{enumerate}
    \item \textbf{Crear plan}: para crear un plan un usuario ha tenido que guardar previamente una película tras reconocerla con la cámara y al entrar a la interfaz de la información de dicha película podrá presionar el botón para crear un plan con dicha película.
    \item \textbf{Unirse a un plan}: dependiendo de si el plan es privado o público solo podrán unirse los amigos del usuario creador del plan o cualquiera, al entrar en la interfaz que tiene la información de un plan podremos pulsar un botón para unirnos.
    \item \textbf{Información de un plan}: simplemente con presionar en un plan podremos ver la información del mismo, es decir, la película a ver y los usuarios que se han unido.
\end{enumerate}

\paragraph{Películas guardadas:\\}

Las películas guardadas son aquellas que el usuario ha decidido guardar para ver su información más tarde o para posteriormente añadirlas a un plan.
\\
\textbf{Funciones:}
\begin{enumerate}
    \item \textbf{Guardar película}: cuando un usuario reconoce una película con la cámara, le aparecerá un botón que le permitirá guardar la película como favorita, para poder ver su información posteriormente o crear un plan con ella.
    \item \textbf{Información de una película}: un usuario puede ver la información de una película que haya guardado con presionar en la misma. Podrá ver una pequeña sinopsis, el género y el director, además de la posibilidad de poder valorarla.
\end{enumerate} 
\section{Interfaz de usuario}
\label{makereference3.4}

\section{Sistema de recomendación}
\label{makereference3.5}

\section{Prototipos}
\label{makereference3.6}

\subsection{ARCore} 
\label{makereference3.6.1} 
 
\subsection{Viro Media} 
\label{makereference3.6.2}
\begin{flushleft}
El objetivo del prototipo realizado con \textbf{Viro Media} es reconocer imágenes almacenadas en el dispositivo para mostrar texto y
 objetos virtuales. Además de probar tecnologías de desarrollo móvil web como en este caso \textbf{React Native}
 para plataformas \textbf{iOS} y \textbf{Android}.
\end{flushleft}
\begin{flushleft}
Comenzamos construyendo una interfaz sencilla con botones que nos redirigen a la escena de Realidad Aumentada.
Para esta interfaz utilizamos \textbf{NativeBase} que es una librería que nos permite
realizar una aplicación con apariencias de tipo \textbf{iOS} o \textbf{Android} según el dispositivo.
\end{flushleft}

\begin{figure}[htb]
    \centering
    \makebox[0pt][c]{%
    \begin{minipage}[b]{0.6\linewidth}
    \centering
      \includegraphics[scale=0.4]{figures/chapter-3/viromedia/android.png}
      \caption{Visualización con NativeBase en Android}
    \label{sva}
    \end{minipage}%
    \hspace{0.5cm}
    \begin{minipage}[b]{0.6\linewidth}
    \centering
     \includegraphics[scale=0.4]{figures/chapter-3/viromedia/ios.jpg}
      \caption{Visualización con NativeBase en iOS}
    \label{svb}
    \end{minipage}%
    }%
\end{figure}

\begin{flushleft}
Para la escena de Realidad Aumentada mostramos texto y al detectar el póster de Pantera Negra,
 reacciona mostrando una animación de dicho súper héroe saliendo del póster.
\end{flushleft}
 
\begin{figure}[H]
    \centering
    \includegraphics[width=3in]{figures/chapter-3/viromedia/blackpanther.png}
    \caption{Visualización de RA}
\end{figure}

\begin{flushleft}
Una de las ventajas que apreciamos fue la facilidad del lenguaje, en este caso \textbf{Javascript},
 utilizando la popular librería \textbf{ReactJS} y la buena documentación de \textbf{Viro Media}
 que hacian que el proceso de codificación fuera agradable.
\end{flushleft}
\begin{flushleft}
Uno de los problemas que presentaba este prototipo era que las dependencias de \textbf{Viro Media} entraban en conflicto con las de \textbf{NativeBase}
imposibilitándonos la forma de encontrar versiones compatibles. Utilizamos las últimas, que a pesar de lanzar
 advertencias, funcionaba en el ejemplo realizado.
Otro problema fue la compilación de la aplicación, \textbf{Viro Media} tiene una aplicación para probar lo
 que desarrollamos conectándose a nuestro ordenador a través de la red. El problema es
 que algunos recursos, como los iconos que utilizaba \textbf{NativeBase}, no eran descargados, por lo que la
 mejor forma era probar la versión compilada de \textbf{iOS} y \textbf{Android}. La forma de compilar
 la aplicación era un proceso costoso para los ordenadores, lento y con multitud de problemas según
 se ampliaban las librerías que se utilizan.
\end{flushleft}

\begin{flushleft}
La conlusión que obtuvimos de este prototipo fue que \textbf{Viro Media} y \textbf{React Native} son tecnologías muy prometedoras, pero debido a los
 problemas surgidos y a que todas sus versiones no eran estables vimos un claro riesgo para
 nuestro proyecto.
\end{flushleft}

\newpage
\subsection{Vuforia + Android} 
\label{makereference3.6.3} 
 
\begin{flushleft}
En este prototipo utilizamos la librería nativa de \textbf{Vuforia} para \textbf{Android} para 
realizar las pruebas de tecnología de reconocimiento de imágenes tanto en  
local como usando la nube que nos ofrecía \textbf{Vuforia}, para la posterior renderización
de objetos y textos.

Las características tecnológicas de este prototipo son las siguientes:
\end{flushleft}

\begin{enumerate}
    \item La librería de \textbf{Vuforia} para \textbf{Android} está diseñada a muy bajo nivel.
    \item \textbf{Vuforia} para dibujar en 3D usa la librería \textbf{OpenGL}.
    \item \textbf{OpenGL} utiliza una serie de espacios donde se van colocando los elementos: 
    \begin{enumerate}
        \item \textbf{Local space}: Es el espacio local de cada objeto.
        \item \textbf{World space}: Es el mundo donde se encuentran los objetos.
        \item \textbf{View space}: El mundo visto desde la perspectiva de la cámara.
        \item \textbf{Clip space}: Se integra con la pantalla del móvil y, definiendo los límites visibles, se establecen unas coordenadas de rango (-1,-1) - (1,1).
    \end{enumerate}
    \begin{flushleft}
        Las transformaciones de estos espacios se realizan mediante matrices 4x4, 
        en las que la primera fila hace referencia a la coordenada x, la segunda a la coordenada y y la 
        tercera a la coordenada z, mientras que la última columna hace referencia a los desplazamientos 
        de los objetos en esos 3 ejes.
        \end{flushleft}
        

        
            \begin{figure}[H]
                \centering
                \includegraphics[width=5in]{figures/space-transformation.png}
                \caption{Esquema de los distintos espacios que usa OpenGL}
            \end{figure}

            \begin{figure}[H]
                \centering
                \includegraphics[width=5in]{figures/teapot.png}
                \caption{Ejemplo de un modelo en 3D}
            \end{figure}
    
    \item En \textbf{OpenGL} es necesario escribir código para que las tarjetas gráficas rendericen el modelo 3D,
    el lenguaje que se usa es \textbf{GLSL}. Este código de \textbf{GLSL} se escribe en forma de \textbf{String} y se llama a un método 
    que proporciona \textbf{OpenGL}.
    \begin{figure}[H]
        \centering
        \includegraphics[width=5in]{figures/GLSL.png}
        \caption{Código en GLSL}
    \end{figure}
        
    \item Otro aspecto a tener en cuenta es que \textbf{OpenGL} solo nos ofrece lo básico, no nos ofrece métodos para dibujar 
    directamente objetos sino que hay que seguir un pipeline de procesos para conseguir dibujar algo.
    \newline
    \begin{flushleft}
    Esto consiste en pasar un \textbf{array} de números (cada tres para definir un punto) 
    a las tarjetas gráficas, establecer triángulos entre los puntos (más arrays de números) 
    definir colores a partir de los puntos (más arrays)..., y con el código del shader, ejecutar 
    estos datos.
    \begin{figure}
        \centering
        \includegraphics[width=4in]{figures/pipeline.png}
        \caption{Pipeline de la construcción de un modelo}
    \end{figure}
    \end{flushleft}
    \newpage
    \item Por último como sólo ofrece métodos básicos, no hay métodos de escritura de texto, y la forma que 
    encontramos y que funcione fue usar un bitmap con los caracteres. Rechazamos esto por un principal motivo, para hacer que funciones hay que codificar a muy bajo nivel y 
    nos costaría mucho tiempo y esfuerzo.
    \begin{figure}
        \centering
        \includegraphics[width=5in]{figures/bitmap-font.png}
        \caption{Mapa de bits de caracteres usado}
    \end{figure}
\end{enumerate}
 

\newpage
\subsection{Vuforia + Unity} 
\label{makereference3.6.4}
\begin{flushleft}
    Para realizar este prototipo utilizamos \textbf{Unity} como herramienta básica para realizar la aplicación y \textbf{Vuforia} para dar soporte a la Realidad Aumentada.
    El prototipo a desarrollar consistió en un modelo 3D de un dragón que aparecía al detectar una imagen que previamente habíamos establecido como ``imagen objetivo''.
\end{flushleft}
    \begin{figure}[H]
        \centering
        \includegraphics[width=5in]{figures/prototipoUnity.jpg}
        \caption{Modelo en 3D que aparecía al detectar la imagen}
    \end{figure}
\begin{flushleft}
    Pese a que nadie del equipo había utilizado \textbf{Unity} previamente el resultado fue bastante positivo ya que:
    \begin{enumerate}
    \item \textbf{Unity} resultó ser intuitivo y relativamente fácil en cuanto al aprendizaje de las funcionalidades básicas.
    \item \textbf{Vuforia} parecía estar muy probada e incluía de serie muchas funcionalidades.
    \item \textbf{Vuforia} tenía la opción de utilizar un \textbf{Cloud} para almacenar las imágenes objetivo.
    \end{enumerate}
\end{flushleft}

\subsection{Vuforia + Unity + Android} 
\label{makereference3.6.5}
\begin{flushleft}
Una vez realizado el prototipo en \textbf{Vuforia} con \textbf{Unity} comenzamos a investigar como realizar el resto de la aplicación que no requería de Realidad Aumentada.
\break
Hasta este momento teníamos claro que \textbf{Vuforia} con \textbf{Unity} era la mejor convinación para realizar la parte de Realidad Aumentada, sin embargo, \textbf{Unity} no era igual de intuitivo ni eficaz a la hora de realizar tareas propias de una aplicación "normal", como el desarrollo de interfaces o la lógica.
\break
Por este motivo intentamos buscar la opción de realizar una aplicación en la que la Realidad Aumentada estuviese diseñada en \textbf{Unity} con \textbf{Vuforia} y el resto de la aplicación en Android.
\end{flushleft}
\begin{figure}[H]
        \centering
        \includegraphics[width=1in]{figures/androidUnityVuforia.jpg}
        \caption{Botón que comunicaba Android con Unity}
\end{figure}
\begin{flushleft}
    Finalmente conseguimos tener ambos proyectos independientes, la Realidad Aumentada se desarrollaba en \textbf{Unity} con \textbf{Vuforia} y se exportaba a un proyecto Android donde se encontraba el resto de la aplicación.
    Esto nos permitía realizar la Realidad Aumentada con la herramienta que tras las primeras tomas de contacto habíamos comprobado que era la mejor (\textbf{Unity} con \textbf{Vuforia}) y del mismo modo realizar el resto de la aplicación con la mejor herramienta para esta parte (AndroidStudio).
\end{flushleft}
\begin{flushleft}
    Tras realizar este prototipo, consideramos que estas herramientas podrían ser las que usásemos en la aplicación final puesto que:
    \begin{enumerate}
    \item Como ya habíamos descubierto en el prototipo anterior, \textbf{Unity} era una herramienta muy completa y junto con \textbf{Vuforia} nos proporcionaban todas las herramientas necesarias para cumplir con los casos de uso de Realidad Aumentada que teníamos en mente.
    \item Al haber encontrado la forma de combinar \textbf{Unity + Android} no teníamos que renunciar a ninguna de las dos herramientas. Lo que nos permitía explotar las cosas buenas de ambas herramientas.
    \item La comunicación entre \textbf{Unity} y Android era relativamente sencilla pese a ser dos proyectos distintos.
    \end{enumerate}
\end{flushleft}

\newpage
\subsection{Server en Spring} 
\label{makereference3.6.6}

\begin{flushleft}
    Para la realización de la parte backend de la aplicación decidimos
    incorporar la tecnología de \textbf{Spring} para codificar un \textbf{servicio web REST} en \textbf{Java}
    y el acceso a datos mediante \textbf{MySQL}.
\break
\break
    Para el prototipo seguimos el siguiente tutorial: 
\newline
\href{http://sinbugs.com/como-crear-un-microservicio-o-servicio-web-rest-con-spring-boot-1/}{Cómo crear un microservicio o servicio web REST con Spring Boot}
\break
    que consistía en 3 partes bien definidas para la creación de dicho \textbf{servicio web REST} para la gestión de una entidad de contactos muy simple, se puede observar su estructura
    en la figura 3.6.
    \begin{figure}[H]
        \centering
        \includegraphics[width=6in]{figures/ContactsEntity.png}
        \caption{Entidad de Contactos}
    \end{figure}
\break
\break
    También se investigaron distintas formas de realizar el acceso a la base de datos desde el servidor pero finalmente nos decantamos por usar la
    clase \textbf{JPARepository} o \textbf{CRUDRepository}, las cuales nos ofrecen ya implementados los métodos típicos de las operaciones \textbf{CRUD}, además de la opción 
    de poder crear nuestros propios métodos.
\end{flushleft}

\begin{flushleft}
    Para poder probar las distintas peticiones de tipo \textbf{POST} y \textbf{GET}, que realizamos en local, usamos la herramienta 
    \textbf{Postman}, ver figura 3.7.
    \begin{figure}[H]
        \centering
        \includegraphics[width=6in]{figures/Postman.png}
        \caption{Postman}
    \end{figure}
    Para este prototipo decidimos usar \textbf{MySQL} como sistema de gestión de bases de datos relacional, aunque
    a la hora de probar a levantar nuestro servidor de prueba tuvimos que rehacer este prototipo, además de adaptarlo para 
    que gestionara entidades de películas, y que usara \textbf{PostgreSQL}, además de cambiar una serie de anotaciones y limpiar 
    el archivo \textbf{pom.xml} de líneas de código innecesarias, ver figura 3.8, que es el que contiene las dependencias de nuestro proyecto.
    \begin{figure}[H]
        \centering
        \includegraphics[width=6in]{figures/PomXML.png}
        \caption{Archivo pom.xml}
    \end{figure}
\end{flushleft}